{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from src.nlp_dependency_analysis.load_aozora import load_aozora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = load_aozora()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['メロスは激怒した', '必ず、かの邪智暴虐の王を除かなければならぬと決意した', 'メロスには政治がわからぬ']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "460"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GiNZA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.cache/pypoetry/virtualenvs/nlp-dependency-analysis-9TtSrW0h-py3.9/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import ginza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"ja_ginza\")\n",
    "\n",
    "def analyze_ginza(text: str):\n",
    "    ret = {}\n",
    "    phrase_func = lambda x: x\n",
    "    doc = nlp(text)\n",
    "    for sentence in doc.sents:\n",
    "        for token in ginza.bunsetu_head_tokens(sentence):\n",
    "            for _relation, sub_phrase in ginza.sub_phrases(token, phrase_func):\n",
    "                ret[sub_phrase] = phrase_func(token)\n",
    "    return dict(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{毎日: 食べ, 定食: 食べ}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_ginza(\"毎日焼肉定食を食べます\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 460/460 [00:04<00:00, 92.42it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.99 s, sys: 40.6 ms, total: 5.03 s\n",
      "Wall time: 4.98 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = [ analyze_ginza(t) for t in tqdm(texts) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ja_ginza_electra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot find the requested files in the cached path and outgoing traffic has been disabled. To enable model look-ups and downloads online, set 'local_files_only' to False.\n",
      "trying to download model from huggingface hub: megagonlabs/transformers-ud-japanese-electra-base-ginza-510 ...\n",
      "Downloading: 100%|██████████| 815/815 [00:00<00:00, 593kB/s]\n",
      "Downloading: 100%|██████████| 414M/414M [00:50<00:00, 8.59MB/s] \n",
      "succeded\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"ja_ginza_electra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/460 [00:00<?, ?it/s]/root/.cache/pypoetry/virtualenvs/nlp-dependency-analysis-9TtSrW0h-py3.9/lib/python3.9/site-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
      "100%|██████████| 460/460 [00:32<00:00, 13.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 17s, sys: 0 ns, total: 3min 17s\n",
      "Wall time: 33 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = [ analyze_ginza(t) for t in tqdm(texts) ]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d460c1174ea8b7405ae827f9763f0789f53d4be33152adf04e32ff20b659dfbb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('nlp-dependency-analysis-9TtSrW0h-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
